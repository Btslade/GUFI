{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73242b30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e205ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50518d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop(list1):\n",
    "    list1.pop(0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d321b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(list1)\n",
    "pop(list1)\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5df6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = graphing_objects.Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434ef566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302b5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544ca1a5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ee5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "import sys\n",
    "import shlex\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "from performance_pkg import graphing_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82161aa",
   "metadata": {},
   "source": [
    "## Implementing arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ff71b",
   "metadata": {},
   "source": [
    "User will provide what the delimeter is, but instead the cmake debug values\n",
    "\n",
    "user should also provide path to their list of commands\n",
    "\n",
    "user should provide path to store csvs/parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68000d",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56034c4c",
   "metadata": {},
   "source": [
    "We need to ensure that these are seperated by executable and debug value\n",
    "\n",
    "rememeber there are 2 \"string types\" \" \" and \":\" so ensure that each executable and debug values use the correct option of those 2 options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe394c",
   "metadata": {},
   "source": [
    "### Example of checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe6b26",
   "metadata": {},
   "source": [
    "If (cumulative_time):\n",
    "    use : delimeter\n",
    "    \n",
    "If (gufi_trace2index && subdircount):\n",
    "    use whitespace delimeter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3375add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_whitespace(lines):\n",
    "    lines = [item.strip() for item in result.split('\\n')]\n",
    "    lines = [item.strip() for item in lines[line].split(' ')]\n",
    "    return lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29a080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_escape_chars (s):\n",
    "    escape_chars = ['\\n', '\\r', '\\t', '\\b', '\\f']\n",
    "    for escape_char in escape_chars:\n",
    "        s = s.replace(escape_char, \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_keys_in_csv(csv_file_name):\n",
    "    command = shlex.split(f'sed -n 1p {csv_file_name}')\n",
    "    p = subprocess.Popen(command, stdout=PIPE)\n",
    "    first_line, _ = p.communicate() \n",
    "    first_line = first_line.decode('ascii')\n",
    "    first_line=remove_escape_chars(first_line)\n",
    "    csv_keys = first_line.split(',')\n",
    "    return csv_keys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9731a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_colon(command_result):\n",
    "    #test = command_result.split('\\n')\n",
    "    dictionary = {}\n",
    "    for item in command_result:\n",
    "        if item == '':\n",
    "            command_result.remove(item)\n",
    "            continue\n",
    "        item = item.split(':')\n",
    "        item[0] = item[0].lstrip()\n",
    "        item[1] = item[1].lstrip() \n",
    "        update_dict={item[0]:item[1]}\n",
    "        dictionary.update(update_dict)\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccca2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_colon(command_result):\n",
    "\n",
    "    command_result = command_result.split(':')\n",
    "    command_result[0] = command_result[0].lstrip()\n",
    "    command_result[1] = command_result[1].lstrip() \n",
    "    update_dict={command_result[0]:command_result[1]}\n",
    "    \n",
    "    return update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba03fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_line(command):\n",
    "    command = shlex.split(command)\n",
    "    p = subprocess.Popen(command, stderr=PIPE)\n",
    "    _, command_result= p.communicate()\n",
    "    command_result = command_result.decode('ascii')\n",
    "    return command_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a452f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_extract(file_lines):\n",
    "    result_list = []\n",
    "    result = \"\"\n",
    "    for line in file_lines:\n",
    "        result = run_line(line)\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab43ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(list_of_commands):\n",
    "    f = open(list_of_commands,\"r\")\n",
    "    lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f5e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(csv_file_name, list_of_rows, keysList):\n",
    "    path = Path(csv_file_name)\n",
    "    file_exists = path.is_file()\n",
    "    with open(csv_file_name, 'a') as csvfile:\n",
    "        i = csv.DictWriter(csvfile, fieldnames = keysList)\n",
    "        if not file_exists:\n",
    "            i.writeheader()\n",
    "            quick_fix = []\n",
    "            quick_fix.append(list_of_rows)\n",
    "            i.writerows(quick_fix)\n",
    "            return\n",
    "        #if keys dont match is the next step here\n",
    "        quick_fix = []\n",
    "        quick_fix.append(list_of_rows)\n",
    "        i.writerows(quick_fix)\n",
    "    #https://pythonguides.com/python-dictionary-to-csv/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af849b80",
   "metadata": {},
   "source": [
    "### This clean is just a place holder \n",
    "\n",
    "\n",
    "This will evolve to take the first word out of a line, and the first number and set them as a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a985d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53050969/python-capture-next-word-after-specific-string-in-a-text\n",
    "\n",
    "def clean_gufi_trace2index(command_result):\n",
    "    #define dict\n",
    "    #get Scout value\n",
    "    update_dict = {}\n",
    "    if \"Scouts took total of\" in command_result:\n",
    "        scout = command_result.split(\"Scouts took total of \", 2)\n",
    "        scout = scout[1].split(\" \")\n",
    "        scout = scout[0]\n",
    "        scout = scout + 's'\n",
    "        update_dict={'Scouts':scout}\n",
    "    \n",
    "    if \"main completed in\" in command_result:\n",
    "        main = command_result.split(\"main completed in \", 2)\n",
    "        main = main[1].split(\" \")\n",
    "        main = main[0]\n",
    "        main = main + 's'\n",
    "\n",
    "        update_dict = {'Main':main}\n",
    "    \n",
    "    \n",
    "    #remove unnecessary strings\n",
    "    \n",
    "    return update_dict\n",
    "    \n",
    "    #print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb0cb02",
   "metadata": {},
   "source": [
    "### gufi_trace2index place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17fe39d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gufi_trace2index(command_result):\n",
    "    command_result = command_result.split('\\n')\n",
    "    command_dictionary = {}\n",
    "    for i in command_result:\n",
    "        if \"Scouts took total of\" in i or \"main completed\" in i:\n",
    "            command_dictionary.update(clean_gufi_trace2index(i))\n",
    "        elif i == '':\n",
    "            continue\n",
    "        else:\n",
    "            command_dictionary.update(split_colon(i))\n",
    "    keysList = [key for key in command_dictionary]\n",
    "    data_to_csv('gufi_trace2index.csv', command_dictionary, keysList)\n",
    "    print(command_dictionary)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89aa9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gufi_query(command_result):\n",
    "    command_result = command_result.split('\\n')\n",
    "    command_dictionary = {}\n",
    "    for i in command_result:\n",
    "        if i == '': #there are some blank values extracted, this skips them\n",
    "            continue\n",
    "        command_dictionary.update(split_colon(i))\n",
    "    keysList = [key for key in command_dictionary]\n",
    "    #csv_keys = read_keys_in_csv('gufi_query.csv') will go here later\n",
    "    #check if columns in csv match total columns in data method goes here\n",
    "    data_to_csv('gufi_query.csv', command_dictionary, keysList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dfecf4",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37d0f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-a7b15d2f943d>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a7b15d2f943d>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    iterator = iterator + 1\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "command_file_lines = open_file(\"./list_of_commands.txt\")\n",
    "command_outputs = run_and_extract(command_file_lines)\n",
    "iterator = 0\n",
    "for i in command_file_lines:\n",
    "    if 'gufi_query' in i:\n",
    "        gufi_query(command_outputs[iterator])\n",
    "    if 'gufi_trace2index' in i:\n",
    "        gufi_trace2index(command_outputs[iterator])\n",
    "    #if 'gufi_trace2index' in i:\n",
    "        \n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6a140",
   "metadata": {},
   "source": [
    "## Show command file lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07e00191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GUFI/build/src/gufi_query -S \"SELECT * FROM SUMMARY\" -E \"SELECT * FROM pentries\" tree/GUFI/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in command_file_lines:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd19b4e",
   "metadata": {},
   "source": [
    "## Show outputs of commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f89170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up globals:                             0.00s\n",
      "set up intermediate databases:              0.00s\n",
      "thread pool:                                0.06s\n",
      "    open directories:                       0.00s\n",
      "    attach index:                           0.02s\n",
      "    xattrprep:                              0.00s\n",
      "    addqueryfuncs:                          0.00s\n",
      "    get_rollupscore:                        0.00s\n",
      "    descend:                                0.00s\n",
      "        check args:                         0.00s\n",
      "        check level:                        0.00s\n",
      "        check level <= max_level branch:    0.00s\n",
      "        while true:                         0.00s\n",
      "            readdir:                        0.00s\n",
      "            readdir != null branch:         0.00s\n",
      "            strncmp:                        0.00s\n",
      "            strncmp != . or ..:             0.00s\n",
      "            snprintf:                       0.00s\n",
      "            lstat:                          0.00s\n",
      "            isdir:                          0.00s\n",
      "            isdir branch:                   0.00s\n",
      "            access:                         0.00s\n",
      "            set:                            0.00s\n",
      "            clone:                          0.00s\n",
      "            pushdir:                        0.00s\n",
      "    check if treesummary table exists:       0.00s\n",
      "    sqltsum:                                0.00s\n",
      "    sqlsum:                                 0.01s\n",
      "    sqlent:                                 0.02s\n",
      "    xattrdone:                              0.00s\n",
      "    detach index:                           0.00s\n",
      "    close directories:                      0.00s\n",
      "    restore timestamps:                     0.00s\n",
      "    free work:                              0.00s\n",
      "    output timestamps:                      0.00s\n",
      "aggregate into final databases:             0.00s\n",
      "print aggregated results:                   0.00s\n",
      "clean up globals:                           0.00s\n",
      "\n",
      "Threads run:                                192\n",
      "Queries performed:                          960\n",
      "Rows printed to stdout or outfiles:         1764\n",
      "Total Thread Time (not including main):     0.05s\n",
      "Real time (main):                           0.06s\n",
      "\n",
      "set up globals:                             0.00s\n",
      "set up intermediate databases:              0.00s\n",
      "thread pool:                                0.05s\n",
      "    open directories:                       0.00s\n",
      "    attach index:                           0.02s\n",
      "    xattrprep:                              0.00s\n",
      "    addqueryfuncs:                          0.00s\n",
      "    get_rollupscore:                        0.00s\n",
      "    descend:                                0.00s\n",
      "        check args:                         0.00s\n",
      "        check level:                        0.00s\n",
      "        check level <= max_level branch:    0.00s\n",
      "        while true:                         0.00s\n",
      "            readdir:                        0.00s\n",
      "            readdir != null branch:         0.00s\n",
      "            strncmp:                        0.00s\n",
      "            strncmp != . or ..:             0.00s\n",
      "            snprintf:                       0.00s\n",
      "            lstat:                          0.00s\n",
      "            isdir:                          0.00s\n",
      "            isdir branch:                   0.00s\n",
      "            access:                         0.00s\n",
      "            set:                            0.00s\n",
      "            clone:                          0.00s\n",
      "            pushdir:                        0.00s\n",
      "    check if treesummary table exists:       0.00s\n",
      "    sqltsum:                                0.00s\n",
      "    sqlsum:                                 0.01s\n",
      "    sqlent:                                 0.02s\n",
      "    xattrdone:                              0.00s\n",
      "    detach index:                           0.00s\n",
      "    close directories:                      0.00s\n",
      "    restore timestamps:                     0.00s\n",
      "    free work:                              0.00s\n",
      "    output timestamps:                      0.00s\n",
      "aggregate into final databases:             0.00s\n",
      "print aggregated results:                   0.00s\n",
      "clean up globals:                           0.00s\n",
      "\n",
      "Threads run:                                192\n",
      "Queries performed:                          960\n",
      "Rows printed to stdout or outfiles:         1764\n",
      "Total Thread Time (not including main):     0.04s\n",
      "Real time (main):                           0.05s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in command_outputs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be8973",
   "metadata": {},
   "source": [
    "## gufi_trace2index demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89205765",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_result = \"\"\"Scouts took total of 8.28 seconds\n",
    "Files: 13229405\n",
    "Dirs:  1622422 (360989 empty)\n",
    "Total: 14851827\n",
    "Handle Args:               0.36s\n",
    "memset(work):              0.07s\n",
    "Parse directory line:      25.99s\n",
    "dupdir:                    2079.91s\n",
    "copy_template:             4634.53s\n",
    "opendb:                    297.31s\n",
    "Zero summary struct:       0.28s\n",
    "insertdbprep:              35.27s\n",
    "startdb:                   2.48s\n",
    "fseek:                     5.81s\n",
    "Read entries:              122.03s\n",
    "    getline:               5.21s\n",
    "    memset(entry struct):  6.31s\n",
    "    Parse entry line:      50.51s\n",
    "    free(entry line):      0.61s\n",
    "    sumit:                 1.47s\n",
    "    insertdbgo:            54.18s\n",
    "stopdb:                    34.76s\n",
    "insertdbfin:               1.61s\n",
    "insertsumdb:               89.62s\n",
    "closedb:                   17.92s\n",
    "cleanup:                   0.18s\n",
    "\n",
    "Directories created:       1622423\n",
    "Files inserted:            13229405\n",
    "main completed in 36.41 seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "509a90c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scouts': '8.28s', 'Files': '13229405', 'Dirs': '1622422 (360989 empty)', 'Total': '14851827', 'Handle Args': '0.36s', 'memset(work)': '0.07s', 'Parse directory line': '25.99s', 'dupdir': '2079.91s', 'copy_template': '4634.53s', 'opendb': '297.31s', 'Zero summary struct': '0.28s', 'insertdbprep': '35.27s', 'startdb': '2.48s', 'fseek': '5.81s', 'Read entries': '122.03s', 'getline': '5.21s', 'memset(entry struct)': '6.31s', 'Parse entry line': '50.51s', 'free(entry line)': '0.61s', 'sumit': '1.47s', 'insertdbgo': '54.18s', 'stopdb': '34.76s', 'insertdbfin': '1.61s', 'insertsumdb': '89.62s', 'closedb': '17.92s', 'cleanup': '0.18s', 'Directories created': '1622423', 'Files inserted': '13229405', 'Main': '36.41s'}\n"
     ]
    }
   ],
   "source": [
    "gufi_trace2index(command_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96477417",
   "metadata": {},
   "source": [
    "# NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac3151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43315377",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in command_file_lines:\n",
    "    if debug_option == 'cumulative_time'\n",
    "        if 'gufi_query' in i:\n",
    "            gufi_query(command_outputs[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ecbf6",
   "metadata": {},
   "source": [
    "## CSV naming discussion\n",
    "\n",
    "gufi_query <arguments> <csv_filename>\n",
    ".\n",
    ".\n",
    "    \n",
    "lots of argument combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86aa3a1",
   "metadata": {},
   "source": [
    "### What ever user inputs: sort into a specific pattern (keep arguments with flags)\n",
    "\n",
    "collect as many options \n",
    "machine_cpu\n",
    "machine_ram\n",
    "machine_name\n",
    "machine_cores\n",
    "machine_storage_device\n",
    "\n",
    "put these components in a csv, each row at the end will have a specific hash\n",
    "\n",
    "\n",
    "notes (store without including in hash)\n",
    "\n",
    "\n",
    "git commit hash inside of csv\n",
    "ABC ORDER\n",
    " <gufi_query stuff> --machine_name machine name, -- machine_cpu machine cpu, --machine_ram machine ram THINK arg*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a112a6",
   "metadata": {},
   "source": [
    "given some string of data, hash it (python's hash, python's hash library, will do for now),\n",
    "\n",
    "1. user writes their input -> hashed\n",
    "2. user runs another input\n",
    "    if that input hash matches previous input hash -> update the csv with that hash name\n",
    "    else do step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c671b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "gufi_query -j -v ... c\n",
    "\n",
    "(gufi_query_jflag.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb796b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f2f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82f1a64",
   "metadata": {},
   "source": [
    "Current Problems\n",
    "\n",
    "\n",
    "\n",
    "If we add an extra column, we will have to change the header,\n",
    "\n",
    "This means that we will need to first read the csv if it exists and compare the columns with the key list\n",
    "\n",
    "\n",
    "USER NEEDS TO BE ABLE TO CHOSE WHETHER IT APPENDS OR OVER WRITES THE LATEST ROW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175243d",
   "metadata": {},
   "source": [
    "### THINGS TO CHECK\n",
    "\n",
    "if keys match\n",
    "    append\n",
    "\n",
    "if keys dont match\n",
    "    append any unique keys in current data to the keys in the csv file\n",
    "    ensure that appropriate nulls are placed \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b787e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f676df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
